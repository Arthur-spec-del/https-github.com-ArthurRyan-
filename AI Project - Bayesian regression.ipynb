{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Submission code - Bayesian regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP3gDZ0X0Nilpa4DT/7Wbrp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"HXRMvF-J4DzU","executionInfo":{"status":"error","timestamp":1620124704842,"user_tz":-60,"elapsed":2474,"user":{"displayName":"Arthur Ryan","photoUrl":"","userId":"05840229078040012676"}},"outputId":"1c4e9abd-0a6b-4a4f-d89a-67e8481110c6"},"source":["# Arthur Ryan\n","# NCI-AIML course\n","# Student Number #20170386\n","\n","# Bayesian Regression python code\n","\n","from scipy import stats\n","from sklearn.linear_model import BayesianRidge, LinearRegression\n","from sklearn.linear_model import Ridge\n","from array import *\n","from sklearn import datasets, linear_model\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import statsmodels.api as sm\n","import seaborn as sns\n","\n","from google.colab import drive\n","\n","import os\n","path = os.path.abspath(os.curdir)\n","\n","# for Development / Student use\n","# from google.colab import drive\n","# drive.mount('/content/drive/')\n","# df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project-Regression/Project-AI-Mockaroo_training_data_v1.1_BayesRegression.csv') # to match BN code line\n","\n","\n","# *** for Examiner / for submission\n","df = pd.read_csv('Project-AI-Mockaroo_training_data_v1.1_BayesRegression.csv') # i.e. for same directory as python code i.e. the data file is in the same directory as the python code\n","# df = pd.read_csv(path, 'Project-AI-Mockaroo_training_data_v1.1_BayesRegression.csv') # i.e. for same directory as python code i.e. the data file is in the same directory as the python code\n","# df = pd.read_csv('data.csv') # i.e. for same directory as python code i.e. the data file is in the same directory as the python code\n","\n","\n","# import csv\n","# with open('Project-AI-Mockaroo_training_data_v1.1_BayesRegression.csv', 'r') as file: # i.e. for same directory as python code i.e. the data file is in the same directory as the python code\n","#    reader = csv.reader(file)\n","#    df = pd.DataFrame(reader)\n","\n","\n","\n","for i in range (0, 25000):\n","    # X = df[['TotalMissionCost','Unused_Capacity','Cycle time (days)','Ship hire cost per day','Arrival time']] # .loc[0:25000] # does not work ->  .iloc[:,-1]\n","    X = df[['CostCycleTimeShipHire','Unused_Capacity','Cycle time (days)','Ship hire cost per day','Arrival time']] # .loc[0:25000] # does not work ->  .iloc[:,-1]\n","\n","# *** Correlation Matrix and graph\n","X_corr = round(X.corr(),2)\n","print('\\nCorrelation Matrix\\n',X_corr)\n","\n","# X_corr = X.corr()\n","axis_corr = sns.heatmap(\n","X_corr,\n","vmin=-1, vmax=1, center=0,\n","cmap=sns.diverging_palette(50, 500, n=500),\n","square=True \n",")\n","\n","data_array = np.asarray(X)\n","\n","#print('\\n*** X = ')\n","#print(X)\n","#print('\\n*** data_array = ')\n","#print(data_array)\n","\n","# Generating simulated data with Gaussian weights\n","# np.random.seed(0)\n","\n","n_samples, n_features = 5, 5 # n_features changed to 1 as count starts at 0 below\n","\n","# Create weights with a precision lambda_ of 4.\n","lambda_ = 4.\n","w_temp = np.zeros((n_features,n_samples))\n","w = np.zeros((n_features,n_samples))\n","#print('\\nw = np.zeros((n_features, n_samples))')\n","#print(w_temp)\n","\n","# Only keep 5 weights of interest\n","# relevant_features = np.random.randint(0, n_features, 1)\n","relevant_features = [0,1,2,3,4]\n","for j in relevant_features:\n","  for i in range(0,5,1):\n","      w_temp[j][i] = stats.norm.rvs(loc=0, scale=1. / np.sqrt(lambda_))\n","      w[j][i] = abs(w_temp[j][i])\n","\n","#print('\\nw_temp[j][i] = ',w_temp)\n","#print('\\nw[j][i] = ',w)\n","\n","# Create noise with a precision alpha of 50.\n","alpha_ = 100. # was 50 in previous iteration\n","noise = stats.norm.rvs(loc=0, scale=1. / np.sqrt(alpha_), size=n_samples)\n","\n","# print('\\nnoise = ',noise)\n","\n","y = np.dot(data_array, w) + noise\n","\n","#print('\\ny = np.dot(data_array, w)\\n = ',y)\n","\n","# #############################################################################\n","# Fit the Bayesian Ridge Regression and an OLS for comparison\n","clf = BayesianRidge(fit_intercept=True, compute_score=True)\n","# clf.fit(X, y)\n","\n","#print ('\\nX.shape[0] = ', X.shape[0])\n","#print ('Y.shape[0] = ', y.shape[0])\n","\n","#print ('\\nX.shape[1] = ', X.shape[1])\n","#print ('Y.shape[1] = ', y.shape[1],'\\n')\n","\n","# *** flattening the y output 2 dimension array to a one dimaension vector for bayesian regression fitting\n","y_temp = (y[:,0] + y[:,1] + y[:,2] + y[:,3] + y[:,4])  # trying to make a scalar of the 25,000 rows times 5 columns of data\n","\n","# y_temp.shape[0]\n","\n","# print('\\ny_temp',y_temp,'\\n')\n","\n","clf.set_params(n_iter=10,)\n","\n","clf.fit(data_array, y_temp)\n","\n","ols = LinearRegression()\n","\n","ols.fit(data_array, y_temp)\n","\n","# Parameters list\n","# print('\\nParameters list = ',clf. get_params(deep=True))\n","# print('\\nParameter estimators = ',clf.set_params(**params))¶\n","\n","# #############################################################################\n","# Visualisations\n","# Plot true weights, estimated weights, histogram of the weights, and\n","# predictions with standard deviations\n","\n","# Value of the weights - graph\n","lw = 2\n","plt.figure(figsize=(6, 6))\n","plt.title(\"Weights of the model\")\n","plt.plot(clf.coef_, color='lightgreen', linewidth=lw,\n","         label=\"Bayesian Ridge estimate\")\n","plt.plot(w, color='gold', linewidth=lw, label=\"Ground truth\")\n","plt.plot(ols.coef_, color='navy', linestyle='--', label=\"OLS estimate\")\n","plt.xlabel(\"Features\")\n","plt.ylabel(\"Values of the weights\")\n","plt.legend(loc=\"best\", prop=dict(size=12))\n","\n","\n","# Histogram of the weights - graph\n","plt.figure(figsize=(6, 6))\n","plt.title(\"Histogram of the weights\")\n","plt.hist(clf.coef_, bins=n_features, color='gold', log=True,\n","         edgecolor='black')\n","plt.scatter(clf.coef_[relevant_features], np.full(len(relevant_features), 5.),\n","            color='navy', label=\"Relevant features\")\n","plt.ylabel(\"Features\")\n","plt.xlabel(\"Values of the weights\")\n","plt.legend(loc=\"upper left\")\n","\n","# Marginal log likelihood - graph\n","plt.figure(figsize=(6, 6))\n","plt.title(\"Marginal log-likelihood\")\n","plt.plot(clf.scores_, color='navy', linewidth=lw)\n","plt.ylabel(\"Score\")\n","plt.xlabel(\"Iterations\")\n","\n","\n","# Plotting some predictions for polynomial regression\n","# Plotting some predictions for polynomial regression\n","# Plotting some predictions for polynomial regression\n","def f(x, noise_amount):\n","    y = np.sqrt(x) * np.sin(x)\n","    noise = np.random.normal(0, 1, len(x))\n","    return y + noise_amount * noise\n","\n","degree = 10\n","X = np.linspace(0, 10, 100)\n","y = f(X, noise_amount=0.1)\n","\n","clf_poly = BayesianRidge()\n","clf_poly.fit(np.vander(X, degree), y)\n","\n","X_plot = np.linspace(0, 11, 25)\n","y_plot = f(X_plot, noise_amount=0)\n","y_mean, y_std = clf_poly.predict(np.vander(X_plot, degree), return_std=True)\n","plt.figure(figsize=(6, 6))\n","plt.errorbar(X_plot, y_mean, y_std, color='navy',\n","             label=\"Polynomial Bayesian Ridge Regression\", linewidth=lw)\n","plt.plot(X_plot, y_plot, color='gold', linewidth=lw,\n","         label=\"Ground Truth\")\n","plt.ylabel(\"Output - Value of Weights\")\n","plt.xlabel(\"Feature 1 to 5: CostCycleTime(SH) ; CycleTime ; ShipHire ; TimeNow ; TimeArrival\")\n","plt.legend(loc=\"lower left\")\n","plt.show()\n","\n","# Predict using the Bayesian regression model.\n","clf.score(data_array, y_temp) # -> Return the coefficient of determination  of the prediction\n","print('\\n*** CLF score = ',clf.score(data_array, y_temp))\n","\n","# *** Prediction ***\n","X = [[100000, 10000, 5, 10000, 18],\n","    [150000, 15000, 10, 20000, 22] ]\n","print('\\nPrediction = ',clf.predict(X,return_std=True))\n","\n","\n","# *** trimming decimal places ***  formatting example\n","# *** trimming decimal places ***  formatting example\n","# *** trimming decimal places ***  formatting example\n","\n","# full precision no formatting added\n","#print(y_temp)\n","#print(\"\\n'Bayesian Model Output/Dependent Variable statistics:'\")\n","#print('\\nDescribe summary statistics listing = \\n',stats.describe(y_temp))\n","#print('\\nStandard Deviation = ',stats.tstd(y_temp))\n","#print('Standard Error of the Mean = ',stats.tsem(y_temp))\n","#print('Coefficient of Variation (stdev / mean) = ',stats.variation(y_temp))\n","#print('Trimmed by 10% Mean = ',stats.trim_mean(y_temp,0.10))\n","#print('Inter Quartile Range = ',stats.iqr(y_temp))\n","\n","#TMC_array = np.array(df['TotalMissionCost'])\n","#print('ANOVA results = ',stats.f_oneway(y_temp, TMC_array))\n","#print('Correlation results = ',stats.pearsonr(y_temp, TMC_array))\n","#Sum_of_errors = (y_temp - TMC_array)\n","#print('Average Error in Euros = ', np.mean(Sum_of_errors))\n","#print(\"Average Error in % of TotalMissionCost mean = \", np.mean(abs(Sum_of_errors)) / np.mean(TMC_array),'%')\n","#print(\"Average Error in % of Model Output mean = \", np.mean(abs(Sum_of_errors)) / np.mean(y_temp),'%')\n","#print(\"Standard Error in Euros = \", stats.tsem(Sum_of_errors))\n","#print(\"Standard Error in % of Avg Error= \", stats.tsem(Sum_of_errors) / np.mean(Sum_of_errors),'%')\n","\n","\n","print(\"\\n'Bayesian Model Output/Dependent Variable statistics:'\")\n","print('\\nDescribe summary statistics listing = \\n',stats.describe(y_temp))\n","\n","# print('*** VERSION TWO OUTPUT ***')\n","print(\"\\n**** 'Model Output y Variable' statistics:' ***\")\n","\n","sdev = stats.tstd(y_temp)\n","txt1 = '\\nStandard Deviation = €{:,.2f}'\n","print(txt1.format(sdev))\n","\n","serror = stats.tsem(y_temp)\n","txt2 = '\\nStandard Error of the Mean = €{:,.2f}'\n","print(txt2.format(serror))\n","\n","coeffvartnmean = stats.variation(y_temp)\n","txt3 = '\\nCoefficient of Variation (stdev / mean) = {:,.2f}'\n","print(txt3.format(coeffvartnmean))\n","\n","txt4 = '\\nTrimmed by 10% Mean = €{:,.2f}'\n","print(txt4.format(stats.trim_mean(y_temp,0.10)))\n","\n","txt5 = '\\nInter Quartile Range = €{:,.2f}'\n","print(txt5.format(stats.iqr(y_temp)))\n","\n","#fnumber = stats.f_oneway(y_temp, TMC_array)\n","#txt6 = 'ANOVA results = F number is {:.2f}, SE of F number is {:.2f}'\n","#print(txt6.format(fnumber))\n","\n","TMC_array = np.asarray(df['TotalMissionCost'])\n","corr = stats.pearsonr(y_temp, TMC_array)\n","txt7 = '\\nCorrelation results = {:,.2f}'\n","# print(txt7.format(corr))\n","\n","Sum_of_errors = []\n","Sum_of_errors = (y_temp - TMC_array)\n","soe_mean_tmc = np.mean(Sum_of_errors)\n","txt8 = '\\nAverage Error in Euros = €{:,.2f}'\n","print(txt8.format(soe_mean_tmc))\n","\n","error_percent_of_mean = np.mean(Sum_of_errors) / np.mean(TMC_array)\n","txt9 = \"\\nAverage Error in % of TotalMissionCost mean = {:,.2f}%\"\n","print(txt9.format(error_percent_of_mean))\n","\n","soe_mean_output = np.mean(Sum_of_errors) / np.mean(y_temp)\n","txt10 = \"\\nAverage Error in % of Model Output mean = {:,.2f}%\"\n","print(txt10.format(soe_mean_output))\n","\n","#array_of_errors = np.array(Sum_of_errors)\n","#se_mean_euro = stats.tsem(array_of_errors)\n","#txt11 = \"\\nStandard Error in Euros = €{:,.2f}\"\n","#print(txt11.format(se_mean_euro))\n","\n","se_errors_percent_mean_error = (stats.tsem(Sum_of_errors) / np.mean(Sum_of_errors))\n","txt12 = \"\\nStandard Error in % of Avg Error = {:,.5f}%\"\n","print(txt12.format(se_errors_percent_mean_error))\n","\n","\n","# print('*** VERSION TWO OUTPUT ***')\n","\n","TMC_array = np.asarray(df['TotalMissionCost'])\n","# full precision no formatting added\n","#print(\"\\n'TotalMissionCost' statistics:'\")\n","#print('\\nDescribe summary statistics listing = \\n',stats.describe(TMC_array))\n","#print('Standard Deviation = ',stats.tstd(TMC_array))\n","#print('Standard Error of the Mean = ',stats.tsem(TMC_array))\n","#print('Coefficient of Variation (stdev / mean) = ',stats.variation(TMC_array))\n","#print('Trimmed by 10% Mean = ',stats.trim_mean(TMC_array,0.10))\n","#print('Inter Quartile Range = ',stats.iqr(TMC_array))\n","#print('ANOVA results = ',stats.f_oneway(y_temp, TMC_array))\n","#print('Correlation results = ',stats.pearsonr(TMC_array,y_temp))\n","#Sum_of_errors = (TMC_array - y_temp)\n","#print('Average Error = ', np.mean(Sum_of_errors))\n","#print(\"Average Error in % of TotalMissionCost mean = \", np.mean(abs(Sum_of_errors)) / np.mean(TMC_array),'%')\n","#print(\"Average Error in % of Model Output mean= \", np.mean(abs(Sum_of_errors)) / np.mean(y_temp),'%')\n","#print(\"Standard Error in Euros = \", stats.tsem(Sum_of_errors))\n","#print(\"Standard Error in % of Avg Error= \", stats.tsem(Sum_of_errors) / np.mean(Sum_of_errors),'%')\n","\n","# Formatting added to 2 decimal places\n","print(\"\\n**** 'TotalMissionCost' statistics:' ***\")\n","\n","sdev = stats.tstd(TMC_array)\n","txt1 = '\\nStandard Deviation = €{:,.2f}'\n","print(txt1.format(sdev))\n","\n","serror = stats.tsem(TMC_array)\n","txt2 = '\\nStandard Error of the Mean = €{:,.2f}'\n","print(txt2.format(serror))\n","\n","coeffvartnmean = stats.variation(TMC_array)\n","txt3 = '\\nCoefficient of Variation (stdev / mean) = {:,.2f}'\n","print(txt3.format(coeffvartnmean))\n","\n","txt4 = '\\nTrimmed by 10% Mean = €{:,.2f}'\n","print(txt4.format(stats.trim_mean(TMC_array,0.10)))\n","\n","txt5 = '\\nInter Quartile Range = €{:,.2f}'\n","print(txt5.format(stats.iqr(TMC_array)))\n","\n","#fnumber = stats.f_oneway(y_temp, TMC_array)\n","#txt6 = 'ANOVA results = F number is {:.2f}, SE of F number is {:.2f}'\n","#print(txt6.format(fnumber))\n","\n","corr = stats.pearsonr(TMC_array,y_temp)\n","txt7 = '\\nCorrelation results = {:,.2f}'\n","# print(txt7.format(corr))\n","\n","Sum_of_errors = []\n","Sum_of_errors = (TMC_array - y_temp)\n","soe_mean_tmc = np.mean(Sum_of_errors)\n","txt8 = '\\nAverage Error in Euros = €{:,.2f}'\n","print(txt8.format(soe_mean_tmc))\n","\n","soe_mean_output = np.mean(abs(Sum_of_errors)) / np.mean(y_temp)\n","txt10 = \"\\nAverage Error in % of Model Output mean = {:,.2f}%\"\n","print(txt10.format(soe_mean_output))\n","\n","error_percent_of_mean = np.mean(abs(Sum_of_errors)) / np.mean(TMC_array)\n","txt9 = \"\\nAverage Error in % of TotalMissionCost mean = {:,.2f}%\"\n","print(txt9.format(error_percent_of_mean))\n","\n","# array_of_errors = np.array(Sum_of_errors)\n","# se_mean_euro = stats.tsem(array_of_errors)\n","# txt11 = \"\\nStandard Error in Euros = €{:,.2f}\"\n","# print(txt11.format(se_mean_euro))\n","\n","se_errors_percent_mean_error = (stats.tsem(Sum_of_errors) / np.mean(Sum_of_errors))\n","txt12 = \"\\nStandard Error in % of Avg Error = {:,.5f}%\"\n","print(txt12.format(se_errors_percent_mean_error))\n","\n","res = stats.probplot(Sum_of_errors, plot=plt)\n","plt.figzise=(15,15)\n","plt.show()\n","\n","plt.plot(Sum_of_errors)\n","plt.figzise=(15,15)\n","plt.show()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"],"name":"stderr"},{"output_type":"error","ename":"IsADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-165f2724db55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# *** for Examiner / for submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Project-AI-Mockaroo_training_data_v1.1_BayesRegression.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# i.e. for same directory as python code i.e. the data file is in the same directory as the python code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m# df = pd.read_csv('data.csv') # i.e. for same directory as python code i.e. the data file is in the same directory as the python code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0;34m'are \"c\", \"python\", or \"python-fwf\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 )\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2387\u001b[0m             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m         )\n\u001b[1;32m   2391\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqlrXoe66-bT","executionInfo":{"status":"ok","timestamp":1620124156994,"user_tz":-60,"elapsed":926,"user":{"displayName":"Arthur Ryan","photoUrl":"","userId":"05840229078040012676"}},"outputId":"9842a2af-eef1-4395-f6d7-7e92636e17f0"},"source":["import os\n","print (os.path.abspath(os.curdir))\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]}]}